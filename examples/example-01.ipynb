{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "This notebook will show how an overview of the library. After running each thoth command you can check the results in the dashboard to better understand the flow and the behavior of the system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix working dir\n",
    "import pathlib\n",
    "import os\n",
    "\n",
    "path = os.path.join(pathlib.Path().absolute(), \"../\")\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from pyspark.sql import SparkSession\n",
    "import pydeequ\n",
    "import json\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark context\n",
    "spark = (\n",
    "    SparkSession.builder.config(\"spark.sql.session.timeZone\", \"UTC\")\n",
    "    .config(\"spark.jars.packages\", pydeequ.deequ_maven_coord)\n",
    "    .config(\"spark.jars.excludes\", pydeequ.f2j_maven_coord)\n",
    "    .appName(\"thoth\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics repository connection\n",
    "os.environ[\"DATABASE_URL\"] = os.environ.get(\n",
    "    \"DATABASE_URL\",\n",
    "    \"postgresql+pg8000://postgres:postgres@localhost:5432/metrics_repository\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sample_datasets/temperatures_extended.json\") as f:\n",
    "    json_data = [\n",
    "        {**record, \"ts\": datetime.datetime.fromisoformat(record.get(\"ts\"))}\n",
    "        for record in json.load(f)\n",
    "    ]\n",
    "print(\"Dataset head: \", json_data[:5], \"\\n\")\n",
    "print(\"Dataset tail: \", json_data[-5:], \"\\n\")\n",
    "print(\"Dataset number of records: \", len(json_data), \"\\n\")\n",
    "print(\n",
    "    \"Dataset number of ts daily partitions: \",\n",
    "    len(set(record.get(\"ts\").date() for record in json_data)),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting dataset into history, new scoring batches, and an artificial anomaly batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# historical data with fair confidence of good quality\n",
    "history_df = spark.createDataFrame(\n",
    "    data=[\n",
    "        record\n",
    "        for record in json_data\n",
    "        if record.get(\"ts\").date() <= datetime.date(1981, 12, 25)\n",
    "    ],\n",
    "    schema=\"ts timestamp, value float, sensor string\",\n",
    ")\n",
    "\n",
    "\n",
    "# new batch of data that need quality validation (normal)\n",
    "new_batch_1981_12_26_df = spark.createDataFrame(\n",
    "    data=[\n",
    "        record\n",
    "        for record in json_data\n",
    "        if record.get(\"ts\").date() == datetime.date(1981, 12, 26)\n",
    "    ],\n",
    "    schema=\"ts timestamp, value float, sensor string\",\n",
    ")\n",
    "\n",
    "\n",
    "# new batch of data that need quality validation (normal)\n",
    "new_batch_1981_12_27_df = spark.createDataFrame(\n",
    "    data=[\n",
    "        record\n",
    "        for record in json_data\n",
    "        if record.get(\"ts\").date() == datetime.date(1981, 12, 27)\n",
    "    ],\n",
    "    schema=\"ts timestamp, value float, sensor string\",\n",
    ")\n",
    "\n",
    "\n",
    "# new batch of data that need quality validation (normal)\n",
    "new_batch_1981_12_28_df = spark.createDataFrame(\n",
    "    data=[\n",
    "        record\n",
    "        for record in json_data\n",
    "        if record.get(\"ts\").date() == datetime.date(1981, 12, 28)\n",
    "    ],\n",
    "    schema=\"ts timestamp, value float, sensor string\",\n",
    ")\n",
    "\n",
    "\n",
    "# new batch of data that need quality validation (normal)\n",
    "new_batch_1981_12_29_df = spark.createDataFrame(\n",
    "    data=[\n",
    "        record\n",
    "        for record in json_data\n",
    "        if record.get(\"ts\").date() == datetime.date(1981, 12, 29)\n",
    "    ],\n",
    "    schema=\"ts timestamp, value float, sensor string\",\n",
    ")\n",
    "\n",
    "\n",
    "# new batch of data that need quality validation (normal)\n",
    "new_batch_1981_12_30_df = spark.createDataFrame(\n",
    "    data=[\n",
    "        record\n",
    "        for record in json_data\n",
    "        if record.get(\"ts\").date() == datetime.date(1981, 12, 30)\n",
    "    ],\n",
    "    schema=\"ts timestamp, value float, sensor string\",\n",
    ")\n",
    "# Artificial anomaly: temperatures in fahrenheit instead of celsius\n",
    "new_batch_1981_12_30_anomaly_df = spark.createDataFrame(\n",
    "    data=[\n",
    "        {\n",
    "            \"ts\": record.get(\"ts\"),\n",
    "            \"value\": ((record.get(\"value\")) * 9 / 5) + 32\n",
    "            if record.get(\"value\")\n",
    "            else None,\n",
    "            \"sensor\": record.get(\"sensor\"),\n",
    "        }\n",
    "        for record in json_data\n",
    "        if record.get(\"ts\").date() == datetime.date(1981, 12, 30)\n",
    "    ],\n",
    "    schema=\"ts timestamp, value float, sensor string\",\n",
    ")\n",
    "# Artificial anomaly: one sensor starts to output only null values\n",
    "new_batch_1981_12_30_anomaly2_df = spark.createDataFrame(\n",
    "    data=[\n",
    "        {\n",
    "            \"ts\": record.get(\"ts\"),\n",
    "            \"value\": None\n",
    "            if record.get(\"sensor\") == \"Sensor B\"\n",
    "            else record.get(\"value\"),\n",
    "            \"sensor\": record.get(\"sensor\"),\n",
    "        }\n",
    "        for record in json_data\n",
    "        if record.get(\"ts\").date() == datetime.date(1981, 12, 30)\n",
    "    ],\n",
    "    schema=\"ts timestamp, value float, sensor string\",\n",
    ")\n",
    "\n",
    "\n",
    "# new batch of data that need quality validation (normal)\n",
    "new_batch_1981_12_31_df = spark.createDataFrame(\n",
    "    data=[\n",
    "        record\n",
    "        for record in json_data\n",
    "        if record.get(\"ts\").date() == datetime.date(1981, 12, 31)\n",
    "    ],\n",
    "    schema=\"ts timestamp, value float, sensor string\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Dataset on the Metrics Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import thoth as th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup connection and init the Metrics Repository db\n",
    "from sqlmodel import Session\n",
    "\n",
    "session = Session(th.build_engine())\n",
    "th.init_db(clear=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Steps: Profile the history data, create dataset and optimize models for each metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiling, optimization = th.profile_create_optimize(\n",
    "    df=history_df,\n",
    "    dataset_uri=\"temperatures\",\n",
    "    ts_column=\"ts\",\n",
    "    profiling_builder=th.profiler.SimpleProfilingBuilder(),\n",
    "    optimize_last_n=100,\n",
    "    optimize_target_confidence=0.99,\n",
    "    session=session,\n",
    "    spark=spark,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check [this](http://localhost:8501/?dataset_uri=temperatures&view=%F0%9F%91%A4+Profiling) link to open the UI and see the profiling metrics calculated for the `temperatures` dataset. Try also changing the option from `profiling` to `optimization` to check the models validations and which model and threshold were automatically chosen for each profiling time series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing subsequent new (normal) batches of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.assess_new_ts(\n",
    "    df=new_batch_1981_12_26_df,\n",
    "    ts=datetime.datetime(1981, 12, 26),\n",
    "    dataset_uri=\"temperatures\",\n",
    "    profiling_builder=th.profiler.SimpleProfilingBuilder(),\n",
    "    session=session,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.assess_new_ts(\n",
    "    df=new_batch_1981_12_27_df,\n",
    "    ts=datetime.datetime(1981, 12, 27),\n",
    "    dataset_uri=\"temperatures\",\n",
    "    profiling_builder=th.profiler.SimpleProfilingBuilder(),\n",
    "    session=session,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.assess_new_ts(\n",
    "    df=new_batch_1981_12_28_df,\n",
    "    ts=datetime.datetime(1981, 12, 28),\n",
    "    dataset_uri=\"temperatures\",\n",
    "    profiling_builder=th.profiler.SimpleProfilingBuilder(),\n",
    "    session=session,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.assess_new_ts(\n",
    "    df=new_batch_1981_12_29_df,\n",
    "    ts=datetime.datetime(1981, 12, 29),\n",
    "    dataset_uri=\"temperatures\",\n",
    "    profiling_builder=th.profiler.SimpleProfilingBuilder(),\n",
    "    session=session,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check the `scoring` option in the dashboard to see these last 4 scorings points, which should be marked as OK ðŸŸ¢ (normal behavior according to the system)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing anomalous batches of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.assess_new_ts(\n",
    "    df=new_batch_1981_12_30_anomaly_df,\n",
    "    ts=datetime.datetime(1981, 12, 30, tzinfo=datetime.timezone.utc),\n",
    "    dataset_uri=\"temperatures\",\n",
    "    profiling_builder=th.profiler.SimpleProfilingBuilder(),\n",
    "    session=session,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check the `scoring` option in the dashboard to see this last scoring point, which should be marked as Anomaly ðŸ”´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.assess_new_ts(\n",
    "    df=new_batch_1981_12_30_anomaly2_df,\n",
    "    ts=datetime.datetime(1981, 12, 30, tzinfo=datetime.timezone.utc),\n",
    "    dataset_uri=\"temperatures\",\n",
    "    profiling_builder=th.profiler.SimpleProfilingBuilder(),\n",
    "    session=session,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check the `scoring` option in the dashboard to see this last scoring point, which should be marked as Anomaly ðŸ”´ again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After \"fixing/cleaning\" the new batch, continue subsequent assessment of new batches as they arrive at the data platform\n",
    "Finally these next two runs should correct the anomalous batch, and all metrics in the dashboard should come back to an OK ðŸŸ¢ state again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.assess_new_ts(\n",
    "    df=new_batch_1981_12_30_df,\n",
    "    ts=datetime.datetime(1981, 12, 30, tzinfo=datetime.timezone.utc),\n",
    "    dataset_uri=\"temperatures\",\n",
    "    profiling_builder=th.profiler.SimpleProfilingBuilder(),\n",
    "    session=session,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.assess_new_ts(\n",
    "    df=new_batch_1981_12_31_df,\n",
    "    ts=datetime.datetime(1981, 12, 31, tzinfo=datetime.timezone.utc),\n",
    "    dataset_uri=\"temperatures\",\n",
    "    profiling_builder=th.profiler.SimpleProfilingBuilder(),\n",
    "    session=session,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
