{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "This second example will evaluate a real dataset and how reliably the unsupervised anomaly detection from Thoth can spot quality issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix working dir\n",
    "import pathlib\n",
    "import os\n",
    "\n",
    "path = os.path.join(pathlib.Path().absolute(), \"../\")\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from pyspark.sql import SparkSession, functions as spark_functions\n",
    "import pydeequ\n",
    "import json\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple\n",
    "import time\n",
    "import random\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TZ\"] = \"UTC\"\n",
    "time.tzset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# spark context\n",
    "spark = (\n",
    "    SparkSession.builder.config(\"spark.sql.session.timeZone\", \"UTC\")\n",
    "    .config(\"spark.jars.packages\", pydeequ.deequ_maven_coord)\n",
    "    .config(\"spark.jars.excludes\", pydeequ.f2j_maven_coord)\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True)\n",
    "    .appName(\"thoth\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics repository connection\n",
    "os.environ[\"DATABASE_URL\"] = os.environ.get(\n",
    "    \"DATABASE_URL\",\n",
    "    \"postgresql+pg8000://postgres:postgres@localhost:5432/metrics_repository\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset\n",
    "The `amazon_reviews.json` dataset is a subset from [this](https://nijianmo.github.io/amazon/index.html) big dataset. It contains only the reviews for pet, garden, office and groceries product categories for 2016 and 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sample_datasets/amazon_reviews.json\") as f:\n",
    "    json_data = [\n",
    "        record for record in json.load(f) if record.get(\"timestamp\") >= \"2017-06-15\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'item': '1440572828',\n",
       " 'user': 'A2VQ3O6HQAGF1U',\n",
       " 'rating': 5.0,\n",
       " 'timestamp': '2017-08-09T00:00:00+00:00',\n",
       " 'item_category': 'pet'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2363516"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df = spark.read.json(\n",
    "    spark.sparkContext.parallelize(json_data, numSlices=300),\n",
    "    schema=\"item string, user string, rating float, timestamp timestamp, item_category string\",\n",
    ")\n",
    "dataset_df.cache()\n",
    "dataset_df.createOrReplaceTempView(\"amazon_reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>month</th><th>item_category</th><th>count_category</th></tr>\n",
       "<tr><td>6</td><td>garden</td><td>67482</td></tr>\n",
       "<tr><td>6</td><td>grocery</td><td>37834</td></tr>\n",
       "<tr><td>6</td><td>office</td><td>40130</td></tr>\n",
       "<tr><td>6</td><td>pet</td><td>55113</td></tr>\n",
       "<tr><td>7</td><td>garden</td><td>129035</td></tr>\n",
       "<tr><td>7</td><td>grocery</td><td>76467</td></tr>\n",
       "<tr><td>7</td><td>office</td><td>79423</td></tr>\n",
       "<tr><td>7</td><td>pet</td><td>112757</td></tr>\n",
       "<tr><td>8</td><td>garden</td><td>126458</td></tr>\n",
       "<tr><td>8</td><td>grocery</td><td>81713</td></tr>\n",
       "<tr><td>8</td><td>office</td><td>92704</td></tr>\n",
       "<tr><td>8</td><td>pet</td><td>117226</td></tr>\n",
       "<tr><td>9</td><td>garden</td><td>100409</td></tr>\n",
       "<tr><td>9</td><td>grocery</td><td>76892</td></tr>\n",
       "<tr><td>9</td><td>office</td><td>86909</td></tr>\n",
       "<tr><td>9</td><td>pet</td><td>105830</td></tr>\n",
       "<tr><td>10</td><td>garden</td><td>81565</td></tr>\n",
       "<tr><td>10</td><td>grocery</td><td>74057</td></tr>\n",
       "<tr><td>10</td><td>office</td><td>80082</td></tr>\n",
       "<tr><td>10</td><td>pet</td><td>101767</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+-----+-------------+--------------+\n",
       "|month|item_category|count_category|\n",
       "+-----+-------------+--------------+\n",
       "|    6|       garden|         67482|\n",
       "|    6|      grocery|         37834|\n",
       "|    6|       office|         40130|\n",
       "|    6|          pet|         55113|\n",
       "|    7|       garden|        129035|\n",
       "|    7|      grocery|         76467|\n",
       "|    7|       office|         79423|\n",
       "|    7|          pet|        112757|\n",
       "|    8|       garden|        126458|\n",
       "|    8|      grocery|         81713|\n",
       "|    8|       office|         92704|\n",
       "|    8|          pet|        117226|\n",
       "|    9|       garden|        100409|\n",
       "|    9|      grocery|         76892|\n",
       "|    9|       office|         86909|\n",
       "|    9|          pet|        105830|\n",
       "|   10|       garden|         81565|\n",
       "|   10|      grocery|         74057|\n",
       "|   10|       office|         80082|\n",
       "|   10|          pet|        101767|\n",
       "+-----+-------------+--------------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    select\n",
    "        month(timestamp) as month,\n",
    "        item_category,\n",
    "        count(1) as count_category\n",
    "    from amazon_reviews\n",
    "    group by month, item_category\n",
    "    order by month, item_category\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>count(DISTINCT timestamp)</th></tr>\n",
       "<tr><td>200</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------------------------+\n",
       "|count(DISTINCT timestamp)|\n",
       "+-------------------------+\n",
       "|                      200|\n",
       "+-------------------------+"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select count(distinct timestamp) from amazon_reviews\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting dataset in 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1st part for initial profiling and optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    select *\n",
    "    from amazon_reviews\n",
    "    where timestamp < timestamp('2017-09-23')\n",
    "    \"\"\"\n",
    ").createOrReplaceTempView(\"amazon_reviews_optimization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>count(DISTINCT timestamp)</th></tr>\n",
       "<tr><td>100</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------------------------+\n",
       "|count(DISTINCT timestamp)|\n",
       "+-------------------------+\n",
       "|                      100|\n",
       "+-------------------------+"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select count(distinct timestamp) from amazon_reviews_optimization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2nd part for synthetic anomaly experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    select *\n",
    "    from amazon_reviews\n",
    "    where timestamp >= timestamp('2017-09-23')\n",
    "    \"\"\"\n",
    ").createOrReplaceTempView(\"amazon_reviews_tests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>count(DISTINCT timestamp)</th></tr>\n",
       "<tr><td>100</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------------------------+\n",
       "|count(DISTINCT timestamp)|\n",
       "+-------------------------+\n",
       "|                      100|\n",
       "+-------------------------+"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select count(distinct timestamp) from amazon_reviews_tests\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1st. Creating Dataset on the Metrics Store\n",
    "\n",
    "This chapter will show the initial profiling, dataset creation and optimization using the first 100 points of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import thoth as th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup connection and init the Metrics Repository db\n",
    "from sqlmodel import Session\n",
    "\n",
    "session = Session(th.build_engine())\n",
    "th.init_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiling, optimization = th.profile_create_optimize(\n",
    "    df=spark.table(\"amazon_reviews_optimization\"),\n",
    "    dataset_uri=\"amazon_reviews\",\n",
    "    ts_column=\"timestamp\",\n",
    "    session=session,\n",
    "    spark=spark,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2nd. Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[datetime.datetime(2017, 9, 23, 0, 0),\n",
       " datetime.datetime(2017, 9, 24, 0, 0),\n",
       " datetime.datetime(2017, 9, 25, 0, 0),\n",
       " datetime.datetime(2017, 9, 26, 0, 0),\n",
       " datetime.datetime(2017, 9, 27, 0, 0)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# base models\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Assessment:\n",
    "    expected: bool\n",
    "    actual: bool\n",
    "\n",
    "\n",
    "timestamps = [\n",
    "    record.get(\"timestamp\")\n",
    "    for record in spark.sql(\n",
    "        \"select distinct timestamp from amazon_reviews_tests order by timestamp\"\n",
    "    )\n",
    "    .rdd.map(lambda row: row.asDict())\n",
    "    .collect()\n",
    "]\n",
    "timestamps[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment A\n",
    "Evaluating the next 100 next points \"as is\" without any synthetic anomaly, this is going to be all desired **True Positives**. A true positive in this context is if the point is a normal batch and the system classified as a normal batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_a_assessments: List[Assessment] = []\n",
    "for ts in timestamps:\n",
    "    experiment_a_assessments.append(\n",
    "        Assessment(\n",
    "            expected=True,\n",
    "            actual=th.assess_new_ts(\n",
    "                df=spark.table(\"amazon_reviews_tests\").where(\n",
    "                    f\"timestamp = timestamp('{ts.isoformat()}')\"\n",
    "                ),\n",
    "                ts=ts,\n",
    "                dataset_uri=\"amazon_reviews\",\n",
    "                session=session,\n",
    "                spark=spark,\n",
    "            ),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy for normal points\n",
    "len([a for a in experiment_a_assessments if a.actual == a.expected]) / len(\n",
    "    experiment_a_assessments\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment B\n",
    "Evaluating 25 random days for a synthetic anomaly. The synthetic anomaly for this experiment is simulating a daily batch where events are triplicated. So basically getting tripple the amount of events for that day, compared to the normal behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.datetime(2017, 9, 24, 0, 0),\n",
       " datetime.datetime(2017, 9, 29, 0, 0),\n",
       " datetime.datetime(2017, 10, 10, 0, 0),\n",
       " datetime.datetime(2017, 10, 14, 0, 0),\n",
       " datetime.datetime(2017, 10, 19, 0, 0),\n",
       " datetime.datetime(2017, 10, 23, 0, 0),\n",
       " datetime.datetime(2017, 10, 25, 0, 0),\n",
       " datetime.datetime(2017, 10, 26, 0, 0),\n",
       " datetime.datetime(2017, 10, 28, 0, 0),\n",
       " datetime.datetime(2017, 10, 29, 0, 0),\n",
       " datetime.datetime(2017, 11, 2, 0, 0),\n",
       " datetime.datetime(2017, 11, 8, 0, 0),\n",
       " datetime.datetime(2017, 11, 16, 0, 0),\n",
       " datetime.datetime(2017, 11, 17, 0, 0),\n",
       " datetime.datetime(2017, 11, 24, 0, 0),\n",
       " datetime.datetime(2017, 12, 1, 0, 0),\n",
       " datetime.datetime(2017, 12, 3, 0, 0),\n",
       " datetime.datetime(2017, 12, 6, 0, 0),\n",
       " datetime.datetime(2017, 12, 11, 0, 0),\n",
       " datetime.datetime(2017, 12, 16, 0, 0),\n",
       " datetime.datetime(2017, 12, 18, 0, 0),\n",
       " datetime.datetime(2017, 12, 22, 0, 0),\n",
       " datetime.datetime(2017, 12, 25, 0, 0),\n",
       " datetime.datetime(2017, 12, 30, 0, 0),\n",
       " datetime.datetime(2017, 12, 31, 0, 0)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_timestamps = sorted(random.sample(timestamps, 25))\n",
    "experiment_timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_b_assessments: List[Assessment] = []\n",
    "for ts in experiment_timestamps:\n",
    "    # assessing anomaly batch\n",
    "    anomaly_batch_df = (\n",
    "        spark.table(\"amazon_reviews_tests\")\n",
    "        .unionAll(spark.table(\"amazon_reviews_tests\"))\n",
    "        .unionAll(spark.table(\"amazon_reviews_tests\"))\n",
    "        .where(f\"timestamp = timestamp('{ts.isoformat()}')\")\n",
    "    )\n",
    "    experiment_b_assessments.append(\n",
    "        Assessment(\n",
    "            expected=False,\n",
    "            actual=th.assess_new_ts(\n",
    "                df=anomaly_batch_df,\n",
    "                ts=ts,\n",
    "                dataset_uri=\"amazon_reviews\",\n",
    "                session=session,\n",
    "                spark=spark,\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # cleaning timestamp with normal batch\n",
    "    th.assess_new_ts(\n",
    "        df=spark.table(\"amazon_reviews_tests\").where(\n",
    "            f\"timestamp = timestamp('{ts.isoformat()}')\"\n",
    "        ),\n",
    "        ts=ts,\n",
    "        dataset_uri=\"amazon_reviews\",\n",
    "        session=session,\n",
    "        spark=spark,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy for anomaly points (Experiment B)\n",
    "len([a for a in experiment_b_assessments if a.actual == a.expected]) / len(\n",
    "    experiment_b_assessments\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment C\n",
    "Evaluating 25 random days for a synthetic anomaly. The synthetic anomaly for this experiment is simulating a daily batch where one of the product categories don't receive any review. So basically, from the 4 categories that used to receive daily reviews, only 3 will appear in the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_c_assessments: List[Assessment] = []\n",
    "for ts in experiment_timestamps:\n",
    "    # assessing anomaly batch\n",
    "    anomaly_batch_df = spark.table(\"amazon_reviews_tests\").where(\n",
    "        f\"item_category != 'pet' and timestamp = timestamp('{ts.isoformat()}')\"\n",
    "    )\n",
    "    experiment_c_assessments.append(\n",
    "        Assessment(\n",
    "            expected=False,\n",
    "            actual=th.assess_new_ts(\n",
    "                df=anomaly_batch_df,\n",
    "                ts=ts,\n",
    "                dataset_uri=\"amazon_reviews\",\n",
    "                session=session,\n",
    "                spark=spark,\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # cleaning timestamp with normal batch\n",
    "    th.assess_new_ts(\n",
    "        df=spark.table(\"amazon_reviews_tests\").where(\n",
    "            f\"timestamp = timestamp('{ts.isoformat()}')\"\n",
    "        ),\n",
    "        ts=ts,\n",
    "        dataset_uri=\"amazon_reviews\",\n",
    "        session=session,\n",
    "        spark=spark,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy for anomaly points (Experiment C)\n",
    "len([a for a in experiment_c_assessments if a.actual == a.expected]) / len(\n",
    "    experiment_c_assessments\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment D\n",
    "Evaluating 25 random days for a synthetic anomaly. The synthetic anomaly for this experiment is simulating a daily batch where the review scores changed from 5-star rating to 10-star rating, causing a sudden shift in distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_d_assessments: List[Assessment] = []\n",
    "for ts in experiment_timestamps:\n",
    "    # assessing anomaly batch\n",
    "    anomaly_batch_df = (\n",
    "        spark.table(\"amazon_reviews_tests\")\n",
    "        .withColumn(\"rating\", spark_functions.expr(\"rating * 2\"))\n",
    "        .where(f\"timestamp = timestamp('{ts.isoformat()}')\")\n",
    "    )\n",
    "    experiment_d_assessments.append(\n",
    "        Assessment(\n",
    "            expected=False,\n",
    "            actual=th.assess_new_ts(\n",
    "                df=anomaly_batch_df,\n",
    "                ts=ts,\n",
    "                dataset_uri=\"amazon_reviews\",\n",
    "                session=session,\n",
    "                spark=spark,\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # cleaning timestamp with normal batch\n",
    "    th.assess_new_ts(\n",
    "        df=spark.table(\"amazon_reviews_tests\").where(\n",
    "            f\"timestamp = timestamp('{ts.isoformat()}')\"\n",
    "        ),\n",
    "        ts=ts,\n",
    "        dataset_uri=\"amazon_reviews\",\n",
    "        session=session,\n",
    "        spark=spark,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy for anomaly points (Experiment D)\n",
    "len([a for a in experiment_d_assessments if a.actual == a.expected]) / len(\n",
    "    experiment_d_assessments\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment E\n",
    "Evaluating 25 random days for a synthetic anomaly. The synthetic anomaly for this experiment is simulating a daily batch where some user ids appear as null values, the normal behavior is that this column is 100% complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_e_assessments: List[Assessment] = []\n",
    "for ts in experiment_timestamps:\n",
    "    # assessing anomaly batch\n",
    "    anomaly_batch_df = (\n",
    "        spark.table(\"amazon_reviews_tests\")\n",
    "        .withColumn(\n",
    "            \"user\",\n",
    "            spark_functions.expr(\n",
    "                \"case when item_category = 'garden' then null else user end\"\n",
    "            ),\n",
    "        )\n",
    "        .where(f\"timestamp = timestamp('{ts.isoformat()}')\")\n",
    "    )\n",
    "    experiment_e_assessments.append(\n",
    "        Assessment(\n",
    "            expected=False,\n",
    "            actual=th.assess_new_ts(\n",
    "                df=anomaly_batch_df,\n",
    "                ts=ts,\n",
    "                dataset_uri=\"amazon_reviews\",\n",
    "                session=session,\n",
    "                spark=spark,\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # cleaning timestamp with normal batch\n",
    "    th.assess_new_ts(\n",
    "        df=spark.table(\"amazon_reviews_tests\").where(\n",
    "            f\"timestamp = timestamp('{ts.isoformat()}')\"\n",
    "        ),\n",
    "        ts=ts,\n",
    "        dataset_uri=\"amazon_reviews\",\n",
    "        session=session,\n",
    "        spark=spark,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy for anomaly points (Experiment D)\n",
    "len([a for a in experiment_e_assessments if a.actual == a.expected]) / len(\n",
    "    experiment_e_assessments\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarizing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_true_pred(\n",
    "    assessments_collection: List[List[Assessment]],\n",
    ") -> Tuple[List[bool], List[bool]]:\n",
    "    y_true, y_pred = [], []\n",
    "    for assessment in assessments_collection:\n",
    "        y_true += [a.expected for a in assessment]\n",
    "        y_pred += [a.actual for a in assessment]\n",
    "    return y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,0: True Negative\n",
      "0,1: False Positive\n",
      "1,0: False Negative\n",
      "1,1: True Positive\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7efb9af6bb50>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_true, y_pred = build_true_pred(\n",
    "    assessments_collection=[\n",
    "        experiment_a_assessments,\n",
    "        experiment_b_assessments,\n",
    "        experiment_c_assessments,\n",
    "        experiment_d_assessments,\n",
    "        experiment_e_assessments,\n",
    "    ]\n",
    ")\n",
    "print(\"0,0: True Negative\")\n",
    "print(\"0,1: False Positive\")\n",
    "print(\"1,0: False Negative\")\n",
    "print(\"1,1: True Positive\")\n",
    "ConfusionMatrixDisplay.from_predictions(y_true=y_true, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.98      0.97      0.97       100\n",
      "        True       0.97      0.98      0.98       100\n",
      "\n",
      "    accuracy                           0.97       200\n",
      "   macro avg       0.98      0.97      0.97       200\n",
      "weighted avg       0.98      0.97      0.97       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=y_true, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
